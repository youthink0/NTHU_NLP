{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment02: Find Academic Keyword List\n",
    "Academic Keywords are the words we seldom use ordinarily, but often use in Academic articles. \"This shows\" and \"in conclusion\" are examples of Academic Keywords. This assignment want you to use Rank Ratio and compare two dataset to find Academic Keyword List(AKL).\n",
    "<br><br>\n",
    "One dataset is taken from [`British Academic Written English Corpus(BAWE)`](https://www.coventry.ac.uk/research/research-directories/current-projects/2015/british-academic-written-english-corpus-bawe/), which collect a record of proficient university-level student writing. Hence, BAWE can be seen as Academic data. Another one is called [`Web1T`](https://catalog.ldc.upenn.edu/LDC2006T13), which is presented by Google. Web1T colloct 1 trillion words of English Web, so we can treat it as the representative of common words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram counting\n",
    "This part is almost same as what you need to do in Assignment01. The way to find N-gram is the same as Assignment01. However, tokenization and calculating frequency are a little different. The rules of tokenization in this Assignment are:\n",
    " 1. Ignore case (e.g., \"The\" is the same as \"the\")\n",
    " 2. Split by white spaces <s>and punctuations</s>\n",
    " 3. Ignore all punctuation\n",
    "<br><br>\n",
    "\n",
    "As for calculating frequency, we want you calculating <u>document frequency</u> in this Assignment. <br>What is document frequency? \n",
    "<br>Article 1: \n",
    "> We all know that water masses in the ocean are thought to be transferred by the wind. ...\n",
    "\n",
    "Althought there are at least 2 \"the\" in Article 1, the document frequency of \"the\" is still 1 in this article.<br> No mater how many times does \"the\" show up in Article 1, the document frquency of it is always 1.<br>\n",
    "Article 2: \n",
    "> The film Dantes Peak is about a dormant volcano that suddenly erupts and threatens the nearby town. ...\n",
    "\n",
    "Considering the Article 1 and 2, the document frequency of \"the\" is 2 now.<br>\n",
    "Document frequency can reduce the influence of terms, like \"NLP\".\n",
    "<br><br>\n",
    "<span style=\"color: red\">[ TODO ]</span> Try to modify the functions coded in Assignment01 to <u>calculate document frequencies of all unigram.</u>.\n",
    "\n",
    "Google has calculated the frequency of N-gram, so you only need to do it on BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # [ TODO ] transform to lower case\n",
    "    text = text.lower()\n",
    "    Regtmp = text.split(\" \")\n",
    "    \n",
    "    Reg = [i.strip(punctuation) for i in Regtmp]\n",
    "    #Reg = re.findall(r\"[\\w]+\", text)\n",
    "    # [ TODO ] seperate the words\n",
    "    tokens = Reg\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(tokens):\n",
    "    # [ TODO ]\n",
    "    #frequency = {token:tokens.count(token) for token in set(tokens)}\n",
    "    frequency = Counter(tokens)\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(tokens, n=2):\n",
    "    ... # [ TODO ]\n",
    "    tmp = set() #set() can remove duplicate item automatically\n",
    "    tmp_ngram = \"\"\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        tmp_ngram = tokens[i:i+n]\n",
    "        tmp.add(\" \".join(tmp_ngram)) # will do nothing if Item is already added\n",
    "        \n",
    "        #print(tmp_ngram, \" \".join(tmp_ngram))\n",
    "    tokens = list(tmp)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'united', 'persuade', 'that', 'also', 'distances', 'evolving', 'classes', 'moreover', 'thought', 'pizam', 'on', 'conducted', 'new', 'access', \"kotler's\", 'ultimate', 'feelings', 'approach', 'susceptible', 'which', 'notice', 'rest', 'vacations', 'managers', 'own', 'is', 'relevant', 'improving', '2000', 'participation', 'used', 'marketing', 'seek', 'years', 'showed', 'wall', 'during', 'magazines', 'who', 'world', 'factor', 'areas', 'adventurous', 'through', 'acknowledging', '1982', 'hiking', 'targeted', 'schmoll', 'seekers', 'supports', 'firstly', 'crucial', 'personal', 'interaction', 'stereotypical', 'selected', 'agents', 'described', 'meet', 'stay', 'second', 'postpurchase', 'give', 'al', 'marketplace', 'reasons', 'models', 'relationship', 'version', 'his', '2004', 'shorter', 'support', 'sought', 'best', 'accurate', 'all-inclusive', 'organized', 'horner', 'attracting', 'addition', 'type', 'demographic', 'relatively', 'buy', 'at', 'structure', 'constraints', 'oxford', 'receives', 'influences', 'sell', 'novelty', '1977', 'regard', 'conspirator', 'pitfall', 'relatives']\n",
      "5.440059185028076\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('data', 'BAWE.txt')\n",
    "BAWE_unigram = []\n",
    "#### [ TODO ] calculate document frequency of unigram in BAWE\n",
    "start = time.time()\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    for text in f.readlines():\n",
    "        tokens = tokenize(text)\n",
    "        tmp = get_ngram(tokens, 1)\n",
    "        #BAWE_unigram = tmp + BAWE_unigram\n",
    "        BAWE_unigram[0:0] = tmp # more efficiency than previous row\n",
    "        \n",
    "end = time.time()\n",
    "print(BAWE_unigram[0:100])\n",
    "print(end - start)\n",
    "#print(len(BAWE_unigram))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Web1T Data\n",
    "file_path = os.path.join('data', 'Web1T_unigram.txt')\n",
    "Web1T_unigram_counter = {}\n",
    "with open(file_path,'r', encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        Web1T_unigram_counter[line[0]] = int(line[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank\n",
    "Rank unigrms by their frequencies. The higher the frequency, the higher the rank.(The most frequent unigram ranks 1.)<br>\n",
    "<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Web1T and BAWE.</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web1T_unigram_Rank = {}\n",
    "#### [ TODO ] Rank unigrams for Web1T\n",
    "Web1T_unigram_Rank = calculate_frequency(Web1T_unigram_counter)\n",
    "tmp = sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1],reverse=True)\n",
    "\n",
    "#print(sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1],reverse=True)[:10])\n",
    "for i in range(len(tmp)):\n",
    "    Web1T_unigram_Rank[tmp[i][0]] = i+1\n",
    "#print(sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAWE_unigram_Rank = {}\n",
    "#### [ TODO ] Rank unigrams for BAWE\n",
    "BAWE_unigram_Rank = calculate_frequency(BAWE_unigram)\n",
    "tmp = sorted(BAWE_unigram_Rank.items(), key=lambda x:x[1],reverse=True)\n",
    "\n",
    "for i in range(len(tmp)):\n",
    "    BAWE_unigram_Rank[tmp[i][0]] = i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rank Ratio\n",
    "In this step, you need to map the same unigram in two dataset, and caalculate the Rank Ratio of unigram in BAWE.  <br>Please follow the formula for calculating Rank Ratio:<br> \n",
    "<br>\n",
    "<img src=\"https://imgur.com/vmK7Q1K.jpg\" width=30%><br>\n",
    "If the unigram doesn't appear in Web1T, the rank of it is treated as 1.\n",
    "\n",
    "<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [TODO] calculate all rank ratios of unigrams in BAWE\n",
    "sort_rank = {}\n",
    "for k,v in BAWE_unigram_Rank.items():\n",
    "    if Web1T_unigram_Rank.get(k):\n",
    "        sort_rank[k] = round(float(Web1T_unigram_Rank[k]/BAWE_unigram_Rank[k]),4)\n",
    "    else:\n",
    "        sort_rank[k] = 1\n",
    "#print(sorted(sort_rank.items(), key=lambda x:x[1],reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort the result\n",
    "<span style=\"color: red\">[ TODO ]</span> Please show top 30 uigrams in Rank Ratio and the value of their Rank Ratio in this format: \n",
    "<br>\n",
    "<img src=\"https://imgur.com/AEkiCRr.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank                 unigram              Rank Ratio          \n",
      "1                    cannot               598.8483            \n",
      "2                    firstly              28.7154             \n",
      "3                    conclusion           26.9133             \n",
      "4                    trudgill             21.9784             \n",
      "5                    gleitman             21.245              \n",
      "6                    sibilance            20.2035             \n",
      "7                    generalisability     20.0341             \n",
      "8                    legitimising         19.3991             \n",
      "9                    therefore            18.8841             \n",
      "10                   foregrounded         18.1256             \n",
      "11                   cyanosis             17.8664             \n",
      "12                   plosives             17.8122             \n",
      "13                   assonance            17.3078             \n",
      "14                   emphasises           16.9869             \n",
      "15                   debateable           16.9734             \n",
      "16                   hypothesise          16.8855             \n",
      "17                   behaviourally        16.8829             \n",
      "18                   behaviourist         16.708              \n",
      "19                   pyrexia              16.4203             \n",
      "20                   stoppered            16.4133             \n",
      "21                   hypothesised         16.3039             \n",
      "22                   pipetted             16.1836             \n",
      "23                   dyspnoea             16.0676             \n",
      "24                   lymphadenopathy      15.8275             \n",
      "25                   pasteurised          15.6485             \n",
      "26                   inexistent           15.6275             \n",
      "27                   processual           15.5929             \n",
      "28                   colonisers           15.4664             \n",
      "29                   essay                15.2925             \n",
      "30                   homogenised          15.2499             \n"
     ]
    }
   ],
   "source": [
    "#### [ TODO ] souw the result\n",
    "tmp = sorted(sort_rank.items(), key=lambda x:x[1],reverse=True)\n",
    "for i in range(30):\n",
    "    if i == 0:\n",
    "        print(\"rank\".ljust(20), \"unigram\".ljust(20), \"Rank Ratio\".ljust(20))\n",
    "    print(str(i+1).ljust(20), tmp[i][0].ljust(20), str(tmp[i][1]).ljust(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Bigrams\n",
    "<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.51616096496582\n",
      "rank                 unigram              Rank Ratio          \n",
      "1                    in conclusion        516.2397            \n",
      "2                    however this         417.1183            \n",
      "3                    however the          372.5714            \n",
      "4                    however in           284.5038            \n",
      "5                    however it           247.1333            \n",
      "6                    this essay           227.7991            \n",
      "7                    however there        217.9198            \n",
      "8                    the british          185.8126            \n",
      "9                    the european         155.118             \n",
      "10                   this suggests        138.8269            \n",
      "11                   this shows           106.9427            \n",
      "12                   analysis the         92.4113             \n",
      "13                   therefore it         90.4559             \n",
      "14                   see appendix         90.2655             \n",
      "15                   however a            89.8767             \n",
      "16                   therefore the        86.8495             \n",
      "17                   method the           76.4905             \n",
      "18                   conclusion in        65.1327             \n",
      "19                   however he           63.2176             \n",
      "20                   however to           61.9778             \n",
      "21                   the united           61.5694             \n",
      "22                   the uk               60.2932             \n",
      "23                   therefore this       59.4433             \n",
      "24                   system the           58.7847             \n",
      "25                   example it           58.3225             \n",
      "26                   i shall              58.2541             \n",
      "27                   despite this         57.9263             \n",
      "28                   development the      57.3083             \n",
      "29                   in england           57.1513             \n",
      "30                   example the          56.1404             \n"
     ]
    }
   ],
   "source": [
    "#### [TODO]\n",
    "file_path = os.path.join('data', 'BAWE.txt')\n",
    "BAWE_unigram = []\n",
    "#### [ TODO ] calculate document frequency of unigram in BAWE\n",
    "start = time.time()\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    for text in f.readlines():\n",
    "        tokens = tokenize(text) \n",
    "        tmp = get_ngram(tokens, 2)\n",
    "        BAWE_unigram[0:0] = tmp\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "#print(len(BAWE_unigram))\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "# Read Web1T Data\n",
    "file_path = os.path.join('data', 'Web1T_bigram.txt')\n",
    "Web1T_unigram_counter = {}\n",
    "with open(file_path,'r', encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        Web1T_unigram_counter[line[0]] = int(line[1])\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "Web1T_unigram_Rank = {}\n",
    "#### [ TODO ] Rank bigrams for Web1T\n",
    "Web1T_unigram_Rank = calculate_frequency(Web1T_unigram_counter)\n",
    "tmp = sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1],reverse=True)\n",
    "\n",
    "#print(sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1],reverse=True)[:10])\n",
    "for i in range(len(tmp)):\n",
    "    Web1T_unigram_Rank[tmp[i][0]] = i+1\n",
    "#print(sorted(Web1T_unigram_Rank.items(), key=lambda x:x[1])[:10])\n",
    "\n",
    "\n",
    "\n",
    "BAWE_unigram_Rank = {}\n",
    "#### [ TODO ] Rank bigrams for BAWE\n",
    "BAWE_unigram_Rank = calculate_frequency(BAWE_unigram)\n",
    "tmp = sorted(BAWE_unigram_Rank.items(), key=lambda x:x[1],reverse=True)\n",
    "\n",
    "for i in range(len(tmp)):\n",
    "    BAWE_unigram_Rank[tmp[i][0]] = i+1\n",
    "\n",
    "\n",
    "\n",
    "#### [TODO] calculate all rank ratios of bigrams in BAWE\n",
    "sort_rank = {}\n",
    "for k,v in BAWE_unigram_Rank.items():\n",
    "    if Web1T_unigram_Rank.get(k):\n",
    "        sort_rank[k] = round(float(Web1T_unigram_Rank[k]/BAWE_unigram_Rank[k]),4)\n",
    "    else:\n",
    "        sort_rank[k] = 1\n",
    "\n",
    "#### [ TODO ] souw the result\n",
    "tmp = sorted(sort_rank.items(), key=lambda x:x[1],reverse=True)\n",
    "for i in range(30):\n",
    "    if i == 0:\n",
    "        print(\"rank\".ljust(20), \"bigram\".ljust(20), \"Rank Ratio\".ljust(20))\n",
    "    print(str(i+1).ljust(20), tmp[i][0].ljust(20), str(tmp[i][1]).ljust(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=40492256) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to eeclass. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
